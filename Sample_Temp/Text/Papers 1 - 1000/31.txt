The representation of physical space has traditionally fo- cused on keyphrases such as "Computer Science Building" or "Physics Department" that help us in describing and navigating physical spaces. However, such keyphrases do not capture many properties of physical space. As with the assignment of a keyword to describe a piece of text, these constructs sacrifice meaningful information for abstraction. We propose a system of spatial representation based on richer, emergent language models that encode information lost in keyphrase approaches. We use a mix of wearable and ubiquitous computing environments for the construction of these models. Wearable computers infer language models of their hosts. These language models then act as semantic paint over spaces in a ubiquitous computing environment. Spaces collect this information and construct representa- tions based on interactions with augmented humans. A pro- totype navigation system based on this theory is presented and compared to traditional representations.